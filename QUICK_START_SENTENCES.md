# ğŸš€ Quick Start - Sistema de Estudo de Frases com IA

## âœ… O que foi criado

Criei um **sistema completo de estudo de frases com Professor de IA** integrado ao seu projeto IdiomasBR:

### Backend Completo
- âœ… **Modelos de dados** (Sentence, SentenceReview, UserSentenceProgress, AIConversation)
- âœ… **API REST** com 8 endpoints para frases e IA
- âœ… **IntegraÃ§Ã£o OpenAI** + fallback Ollama local
- âœ… **Sistema RAG** para contexto inteligente
- âœ… **Algoritmo SM-2** para repetiÃ§Ã£o espaÃ§ada
- âœ… **Docker configurado** com Ollama

### Arquivos Criados
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/sentence.py           # Modelos do banco
â”‚   â”œâ”€â”€ schemas/sentence.py          # ValidaÃ§Ã£o Pydantic
â”‚   â”œâ”€â”€ routes/sentences.py          # Endpoints API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ai_teacher.py           # Professor IA
â”‚   â”‚   â””â”€â”€ rag_service.py          # Contexto inteligente
â”‚   â””â”€â”€ core/config.py              # ConfiguraÃ§Ãµes atualizadas
â”œâ”€â”€ import_sentences.py              # Popular banco com exemplos
â””â”€â”€ requirements.txt                 # DependÃªncias atualizadas

docker-compose.yml                   # Com Ollama configurado
.env                                 # VariÃ¡veis de ambiente
SENTENCE_STUDY_GUIDE.md             # DocumentaÃ§Ã£o completa
QUICK_START_SENTENCES.md            # Este arquivo
```

## ğŸ¯ Como Usar

### Passo 1: Configurar API OpenAI (Opcional)

Edite o arquivo `.env`:

```bash
OPENAI_API_KEY=sk-sua-chave-aqui
```

**Nota**: Se nÃ£o configurar, o sistema usa automaticamente Ollama (modelo local).

### Passo 2: Iniciar com Docker

```bash
# Limpar ambiente anterior (se necessÃ¡rio)
docker-compose down -v

# Iniciar todos os serviÃ§os (PostgreSQL + Ollama + Backend + Frontend)
docker-compose up -d

# Acompanhar logs
docker-compose logs -f
```

### Passo 3: Configurar Ollama (Primeira vez)

Baixe um modelo de IA local:

```bash
# Entrar no container Ollama
docker exec -it idiomasbr-ollama bash

# Baixar modelo (escolha um):
ollama pull llama3.2          # Recomendado (4.7GB)
ollama pull llama3.2:1b       # Modelo menor (1.3GB)
ollama pull mistral           # Alternativa (4.1GB)

# Sair do container
exit
```

### Passo 4: Popular Banco com Frases

```bash
# Entrar no container do backend
docker exec -it idiomasbr-backend bash

# Executar script de importaÃ§Ã£o
python import_sentences.py

# Sair
exit
```

Isso adiciona 12 frases de exemplo (A1 a C2).

### Passo 5: Testar API

Acesse a documentaÃ§Ã£o interativa:
- Swagger UI: **http://localhost:8000/docs**
- ReDoc: **http://localhost:8000/redoc**

## ğŸ“¡ Endpoints DisponÃ­veis

### Frases
```bash
GET  /api/sentences/                    # Listar frases
GET  /api/sentences/{id}                # Detalhes de uma frase
GET  /api/sentences/study/session       # Criar sessÃ£o de estudo
POST /api/sentences/study/review        # Registrar revisÃ£o
GET  /api/sentences/recommendations     # RecomendaÃ§Ãµes personalizadas
```

### Professor IA
```bash
POST /api/sentences/ai/ask              # Perguntar ao professor
POST /api/sentences/ai/analyze/{id}     # Analisar frase especÃ­fica
GET  /api/sentences/ai/history          # HistÃ³rico de conversas
```

## ğŸ§ª Testando o Professor IA

### Exemplo 1: Pergunta Geral

```bash
curl -X POST "http://localhost:8000/api/sentences/ai/ask" \
  -H "Authorization: Bearer SEU_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "user_message": "Como usar o Present Perfect?",
    "include_context": false
  }'
```

### Exemplo 2: Analisar Frase EspecÃ­fica

```bash
curl -X POST "http://localhost:8000/api/sentences/ai/analyze/1" \
  -H "Authorization: Bearer SEU_TOKEN"
```

### Exemplo 3: Perguntar com Contexto

```bash
curl -X POST "http://localhost:8000/api/sentences/ai/ask" \
  -H "Authorization: Bearer SEU_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "sentence_id": 1,
    "user_message": "Explique a gramÃ¡tica desta frase",
    "include_context": true
  }'
```

## ğŸ“ Funcionalidades do Professor IA

O professor IA automaticamente:

1. **Explica em PortuguÃªs** - Todas as explicaÃ§Ãµes sÃ£o em portuguÃªs brasileiro
2. **Personaliza por NÃ­vel** - Adapta explicaÃ§Ãµes ao nÃ­vel do aluno (A1-C2)
3. **Usa RAG** - Busca contexto relevante no banco de dados
4. **Identifica Erros Comuns** - Alerta sobre erros tÃ­picos de brasileiros
5. **Fornece Exemplos** - DÃ¡ exemplos prÃ¡ticos de uso
6. **Sugere ExercÃ­cios** - Pode gerar exercÃ­cios personalizados

## ğŸ”§ VariÃ¡veis de Ambiente

```bash
# OpenAI (opcional)
OPENAI_API_KEY=sk-your-key           # Deixe vazio para usar apenas Ollama

# Ollama (modelo local)
OLLAMA_URL=http://ollama:11434       # URL do Ollama no Docker
USE_OLLAMA_FALLBACK=true             # Usar Ollama se OpenAI falhar
```

## ğŸ“Š Como Funciona o RAG

O sistema RAG (Retrieval-Augmented Generation) enriquece as respostas da IA com:

1. **VocabulÃ¡rio Relacionado** - Palavras do banco que aparecem na frase
2. **Progresso do UsuÃ¡rio** - Quantas palavras/frases jÃ¡ estudou
3. **NÃ­vel Estimado** - Baseado no progresso (A1-C2)
4. **HistÃ³rico de RevisÃµes** - Como o usuÃ¡rio performou antes

Isso torna o ensino **personalizado e contextualizado**.

## ğŸ® RepetiÃ§Ã£o EspaÃ§ada (SM-2)

Sistema inteligente que agenda revisÃµes:

| Dificuldade | PrÃ³xima RevisÃ£o | Quando usar |
|-------------|-----------------|-------------|
| **Hard** | 4 horas | NÃ£o lembrei |
| **Medium** | 1 dia | Lembrei com dificuldade |
| **Easy** | 3+ dias | Lembrei facilmente |

## ğŸ› Troubleshooting

### Ollama nÃ£o responde
```bash
# Verificar status
docker ps | grep ollama

# Ver logs
docker logs idiomasbr-ollama

# Reiniciar
docker restart idiomasbr-ollama
```

### OpenAI API Error
- Verifique se `OPENAI_API_KEY` estÃ¡ correto
- Sistema usa Ollama automaticamente como backup

### Banco de dados vazio
```bash
# Popular com frases de exemplo
docker exec -it idiomasbr-backend python import_sentences.py
```

### Erro nas migrations
```bash
# Recriar banco do zero
docker-compose down -v
docker-compose up -d
```

## ğŸ“ PrÃ³ximos Passos

### Frontend (VocÃª pode implementar)
Crie em `frontend/src/app/sentences/page.tsx`:
- Interface de estudo de frases
- Chat com professor IA
- VisualizaÃ§Ã£o de progresso

### Adicionar Mais Frases
Edite `backend/import_sentences.py` e adicione mais exemplos.

### MCP Server (Opcional)
Para integraÃ§Ã£o avanÃ§ada com ferramentas externas.

## ğŸ“š DocumentaÃ§Ã£o Completa

Consulte `SENTENCE_STUDY_GUIDE.md` para documentaÃ§Ã£o detalhada.

## ğŸ‰ Pronto!

Seu sistema de estudo de frases com IA estÃ¡ funcionando!

Endpoints disponÃ­veis em: **http://localhost:8000/docs**
